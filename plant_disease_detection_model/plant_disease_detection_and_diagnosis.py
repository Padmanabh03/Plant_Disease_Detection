# -*- coding: utf-8 -*-
"""Plant Disease Detection and Diagnosis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_YpH2p3PSHQfMIubfhD8-mkI202GvzQi

# Uploading and Unzipping the dataset
"""

from google.colab import files
files.upload()

import os
import json

# Create a directory for Kaggle and move the kaggle.json file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Verify Kaggle setup by listing available datasets
!kaggle datasets list

# Download the dataset
!kaggle datasets download -d emmarex/plantdisease

# List files to confirm download
!ls

import zipfile

zip_filename = 'plantdisease.zip'

# Unzip the dataset
with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall('plantdisease')

print("Dataset extracted successfully.")

# List the contents of the extracted folder
!ls plantdisease

# List contents of 'plantvillage'
print("Contents of 'plantvillage':")
!ls plantdisease/plantvillage

# List contents of 'PlantVillage'
print("\nContents of 'PlantVillage':")
!ls plantdisease/PlantVillage

import os

# Define the path to the PlantVillage directory
plantvillage_dir = 'plantdisease/PlantVillage'  # Change to 'plantdisease/plantvillage' if necessary

# Function to list classes and image counts
def verify_classes(directory):
    classes = os.listdir(directory)
    print(f"Number of classes: {len(classes)}")
    for cls in classes:
        cls_path = os.path.join(directory, cls)
        if os.path.isdir(cls_path):
            num_images = len(os.listdir(cls_path))
            print(f"  {cls}: {num_images} images")
        else:
            print(f"  {cls} is not a directory and will be skipped.")

# Verify classes
print("Verifying classes in PlantVillage:")
verify_classes(plantvillage_dir)

import shutil
import random

# Define base directory
base_dir = 'plantdisease'

# Define source directory
source_dir = os.path.join(base_dir, 'PlantVillage')  # Change to 'plantvillage' if necessary

# Define destination directories
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'validation')
test_dir = os.path.join(base_dir, 'test')

# Define split ratios
train_ratio = 0.7
val_ratio = 0.15
test_ratio = 0.15

# Ensure the destination directories exist
for directory in [train_dir, val_dir, test_dir]:
    if not os.path.exists(directory):
        os.makedirs(directory)

# Get list of classes
classes = [cls for cls in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, cls))]

# Create class subdirectories in train, validation, and test directories
for cls in classes:
    for directory in [train_dir, val_dir, test_dir]:
        cls_path = os.path.join(directory, cls)
        if not os.path.exists(cls_path):
            os.makedirs(cls_path)

# Function to split and copy images
def split_and_copy(source, train, val, test, train_ratio, val_ratio, test_ratio):
    # List all images in the source directory
    all_images = os.listdir(source)
    all_images = [img for img in all_images if img.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]

    # Shuffle the images
    random.shuffle(all_images)

    # Calculate split sizes
    total = len(all_images)
    train_size = int(total * train_ratio)
    val_size = int(total * val_ratio)
    test_size = total - train_size - val_size

    # Split the images
    train_images = all_images[:train_size]
    val_images = all_images[train_size:train_size + val_size]
    test_images = all_images[train_size + val_size:]

    # Function to copy images
    def copy_images(image_list, src, dst):
        for img in image_list:
            src_path = os.path.join(src, img)
            dst_path = os.path.join(dst, img)
            shutil.copy(src_path, dst_path)

    # Copy images to respective directories
    copy_images(train_images, source, train)
    copy_images(val_images, source, val)
    copy_images(test_images, source, test)

    print(f"Total images: {total}")
    print(f"Training: {len(train_images)}")
    print(f"Validation: {len(val_images)}")
    print(f"Test: {len(test_images)}\n")

# Iterate through each class and split the data
for cls in classes:
    print(f"Processing class: {cls}")
    source = os.path.join(source_dir, cls)
    train = os.path.join(train_dir, cls)
    val = os.path.join(val_dir, cls)
    test = os.path.join(test_dir, cls)
    split_and_copy(source, train, val, test, train_ratio, val_ratio, test_ratio)

# Function to count images in a directory
def count_images(directory):
    count = 0
    for cls in os.listdir(directory):
        cls_path = os.path.join(directory, cls)
        if os.path.isdir(cls_path):
            count += len(os.listdir(cls_path))
    return count

print("Number of images in each set:")
print(f"Training set: {count_images(train_dir)} images")
print(f"Validation set: {count_images(val_dir)} images")
print(f"Test set: {count_images(test_dir)} images")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define image parameters
IMAGE_HEIGHT = 224
IMAGE_WIDTH = 224
BATCH_SIZE = 32
NUM_CLASSES = 15  # Update this if you have a different number of classes

# Data augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# No augmentation for validation and test
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Create training data generator
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Create validation data generator
validation_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Create test data generator
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False  # Important for evaluation and predictions
)

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models

# Load the MobileNetV2 model without the top classification layers
base_model = MobileNetV2(
    input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3),
    include_top=False,           # Exclude the top layers
    weights='imagenet'           # Use weights pre-trained on ImageNet
)

# Freeze the base model to prevent its weights from being updated during training
base_model.trainable = False

# Define the input tensor
inputs = layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))

# Pass the inputs through the base model
x = base_model(inputs, training=False)

# Add global average pooling
x = layers.GlobalAveragePooling2D()(x)

# Add a fully connected layer
x = layers.Dense(1024, activation='relu')(x)

# Add dropout for regularization
x = layers.Dropout(0.5)(x)

# Add the output layer with softmax activation for multi-class classification
outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)

# Create the complete model
model = models.Model(inputs, outputs)

# Display the model architecture
model.summary()

from tensorflow.keras import optimizers

model.compile(
    optimizer=optimizers.Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# EarlyStopping to prevent overfitting
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=10,                    # Stop after 10 epochs with no improvement
    restore_best_weights=True       # Restore model weights from the epoch with the best value
)

# ModelCheckpoint to save the best model
checkpoint = ModelCheckpoint(
    'best_model.keras',                # File path to save the model
    monitor='val_loss',
    save_best_only=True,            # Save only the best model
    mode='min'                      # Save when the monitored quantity is minimized
)

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    epochs=50,                       # You can adjust the number of epochs based on performance
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // BATCH_SIZE,
    callbacks=[early_stop, checkpoint]
)

"""# Evaluating the Model on the Test Set

### Load the Best Saved Model
"""

from tensorflow.keras.models import load_model

# Load the best saved model
model = load_model('best_model.keras')
print("Model loaded successfully.")

"""### Evaluate the Model"""

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

"""# Visualizing Results

### Plot Training and Validation Accuracy and Loss
"""

import matplotlib.pyplot as plt

# Plot training & validation accuracy and loss
plt.figure(figsize=(14, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')

plt.tight_layout()
plt.show()

"""### Genrating Classification Report"""

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Generate predictions
predictions = model.predict(test_generator, verbose=1)
predicted_classes = np.argmax(predictions, axis=1)

# Get true labels
true_classes = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

# Classification Report
report = classification_report(true_classes, predicted_classes, target_names=class_labels)
print("Classification Report:")
print(report)

"""### Plotting the Confusion Matrix"""

# Generate confusion matrix
cm = confusion_matrix(true_classes, predicted_classes)

# Plot confusion matrix
plt.figure(figsize=(20, 20))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_labels,
            yticklabels=class_labels)
plt.title('Confusion Matrix')
plt.ylabel('Actual Class')
plt.xlabel('Predicted Class')
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.show()

